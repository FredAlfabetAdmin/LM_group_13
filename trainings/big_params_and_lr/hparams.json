{"model_name": "big_params_and_lr", "seq_length": 16, "batch_size": 32, "learning_rate": 0.005, "num_classes": 5, "epochs": 100, "device": "cuda:0", "lstm_hidden_size": 512, "lstm_num_layers": 2, "bottle_neck_size": 2048, "finetune_from": null, "checkpoint_num": null}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./frame_9.png')#[...,::-1]\n",
    "# Convert the image to HSV color space (Hue, Saturation, Value)\n",
    "hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the color ranges for green, yellow, and white in HSV\n",
    "lower_green = np.array([40, 40, 40])\n",
    "upper_green = np.array([80, 255, 255])\n",
    "\n",
    "lower_yellow = np.array([20, 100, 100])\n",
    "upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "lower_white = np.array([0, 0, 200])\n",
    "upper_white = np.array([255, 30, 255])\n",
    "\n",
    "# Create masks for each color\n",
    "mask_green = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "mask_yellow = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "mask_white = cv2.inRange(hsv_image, lower_white, upper_white)\n",
    "\n",
    "# Set the corresponding color values for each mask\n",
    "img[mask_green > 0] = [0, 255, 0]       # Green cubes\n",
    "img[mask_yellow > 0] = [0, 0, 0]      # Yellow floor\n",
    "img[mask_white > 0] = [0, 0, 255]   # White walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNwithLSTM(nn.Module):\n",
    "    def __init__(self, num_classes=4, lstm_hidden_size=256, lstm_num_layers=1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Reduce 1\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Reduce 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Reduce 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Reduce 4\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.lstm_input_size = 128 * (640//16) * (480//16)\n",
    "\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, lstm_hidden_size, lstm_num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "\n",
    "        # Maybe we can use this fc layer to connect the CNN to the LSTM and reduce the dimensionality of the image.\n",
    "        # self.fc1 = nn.Linear(64 * (640//8) * (480//8), 128)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor(), seq: torch.Tensor()): #x is the new image, seq is the previous sequence it gave\n",
    "        # x, seq = x\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(-1, self.lstm_input_size)  # Adjusted to the new input size\n",
    "        seq = torch.cat([seq[:,1:,:], x.unsqueeze(1)], dim=1)\n",
    "        x, _ = self.lstm(seq)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNwithLSTM()\n",
    "seq_length = 128\n",
    "seq = torch.zeros([1,seq_length,model.lstm_input_size])\n",
    "inp = torch.tensor(np.expand_dims(img.swapaxes(-1, 0).swapaxes(-1, 1), 0), dtype=torch.float32)\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0836, grad_fn=<NllLossBackward0>)\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [14.8302, 12.4078, 11.8303,  ...,  0.0253,  0.0253,  0.0262],\n",
      "         [17.0481, 14.4559, 13.8074,  ...,  0.0249,  0.0249,  0.0258],\n",
      "         [18.9673, 16.2767, 15.5925,  ...,  0.0246,  0.0246,  0.0255]]])\n"
     ]
    }
   ],
   "source": [
    "p, seq_new = model(inp, seq)\n",
    "p = p[0]\n",
    "loss = nn.functional.cross_entropy(p, torch.tensor(1, dtype=torch.long))\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optim.step()\n",
    "optim.zero_grad()\n",
    "seq = seq_new.detach()\n",
    "print(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LM2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
